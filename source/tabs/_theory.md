# Theory

## Tweeting as a Gendered Act of Care

This case study is not at all an attempt to accuse male tweeters of neglecting female panelists or undervaluing their contributions during conferences. Firstly, such an accusation would be largely unfounded (as the Results section shows). Secondly, making such accusations would posit male tweeting behavior (or female tweeting behavior) as a standard from which the other deviates---which would not only be unhelpful but also essentialist. Isolating some immutable female style and some immutable male style in order to make a judgment call about what supposed style is unilaterally _better_ is not what I am after here. Rather, I want to elucidate the types of labor that female tweeters offered the DH community in the panels I went to at MLA16. 

Tweeting is carework when tweets are used to support other scholars, whether that scholar is a panelist, another audience member, or someone not present at the conference or that particular panel. That support may come in the form of preserving and and transmitting their ideas ("[signal boosting](http://everydaylife.globalpost.com/signal-booster-twitter-36719.html)" so that the idea reaches a larger audience), reviewing their work (whether by giving a solid thumbs-up, constructive critique, or something between the two), offering suggestions for further research or revision, or providing citations (whether indicated by the presenter or proactively identified by the tweeter). Instead of allowing one's thoughts to drift, a tweeter consciously makes an effort to have a device ready and remains on the alert for ways to support the presenter and the audience, both inside and outside the room. In the same way, [Clancy's Storifies](https://storify.com/clancynewyork) are also a work of care; as [she theorizes in a tweet](https://twitter.com/clancynewyork/statuses/685891707330781184), "I see conference Storifies as my offsite #DH helpdesk contribution to scholarly communication." Although not all tweeters may not be consciously theorizing why they are doing what they are doing, this carework can contribute powerfully to scholarship. 


## Small Data

My dataset is of 792 tweets is quite small. This small size resulted more or less incidentally, as I did not go into the conference expecting to come away with a small research project. Nonetheless, I argue that this dataset is useful and appropriate for the type and scale of my research question: *Was I right to feel that women in the same panels as me were doing a majority of the Twitter labor being done on behalf of the larger scholarly community?* This is offered as a relatively empirical response to a phenomenon subjectively perceived; it is offered as an early step in finding a method to explain what goes on in conference Twitter within the digital humanities community. It is important to remember that these three panels were digitally inflected and do not necessarily represent tweeters covering other #MLA16 panels, as well as to remember that Twitter users are probably more likely than the general MLA community to identify as digital humanists.

Small data has been presented recently as a useful corrective to the digital humanities' perceived overreliance on big data. In "Six Provocations of Big Data," [Kate Crawford and danah boyd argue](http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1926431) that "in the era of the computational turn, it is increasingly important to recognize the value of 'small data'. Research insights can be found at any level, including at very modest scales" (8). As long as the conclusions claimed do not overreach the scope of their data, these insights can be useful for scholars. [Cheryl Ball agrees, pointing out](http://www.digitalrhetoriccollaborative.org/2013/11/12/from-big-data-to-boutique-data/), "In the rush to embrace big data as a funding stream for large, networked humanities projects, researchers in rhetoric and composition and the digital humanities might miss the value in the thousands, perhaps hundreds of thousands, of uncounted data sets we already have" (par. 5). The present case study has adapted one such uncounted set: Storifies based on conference tweeting.

Scott Weingart, [in his 2014 DH Forum keynote, "The Moral Role of DH in a Data-Driven World,"](http://www.scottbot.net/HIAL/?p=40944) specifies the ethical value of small data by arguing that using only big data makes it "difficult to see the small but endless inequalities that leave women and minorities systematically underappreciated and exploited" (par. 28) Weingart points out that, by contrast, small data is "better at betraying the features of communities, rather than societies" (par. 29). If I want to learn about my own Twitter community---digital humanists who like to tweet at conferences---then small data may in fact be the best data for the job. In short, though I think the _methods_ I outline can be regarded as scalable, I chiefly want to affirm my _results_ insofar as they taken to reflect only the information that I fed into my statistics and figures.

## The Bechdel Test

[The Bechdel test](https://en.wikipedia.org/wiki/Bechdel_test) dates from 1985, when cartoonist Alison Bechdel's comic _Dykes To Watch Out For_ stipulated rules for judging a film's portrayal of women. In [the strip "The Rules,"](http://alisonbechdel.blogspot.com/2005/08/rule.html) Bechdel's character explains, "I only go to a movie if it satisfies three basic requirements. **One**, it has to have at least two women in it who, **two**, talk to each other about, **three**, something besides a man" (panels 4-5). Movies that meet these requirements are considered to portray women as fully rounded characters who are central (not peripheral) to the plot and express interest in issues other than normative heterosexual romance. (Digital humanists may know the test from Apoorv Agarwal et. al's [paper on automating the Bechdel test](http://aclweb.org/anthology/N/N15/N15-1084.pdf) or Scott Selisker's [consideration of the test as a character network](https://www.researchgate.net/publication/284433910_The_Bechdel_Test_and_the_Social_Form_of_Character_Networks).) 

Applied to academic Twitter, then, I wanted to discern whether women's scholarship was adequately represented. As is suggested by the popularity of the recent ["Congrats, you have an all male panel!" Tumblr](http://allmalepanels.tumblr.com/), setting a standard for each tweet or stream featuring at least more than one woman _panelist_ might be unrealistic. Nevertheless, it is a wise goal to champion: as [Jacqueline Wernimont](https://jwernimont.wordpress.com/) pointed out to me, Monica Rogati sketched out precisely such an adaptation of the Bechdel test [in a tweet from November 15, 2015](https://twitter.com/mrogati/status/665962306694615040). Rogati explains a "Bechdel test for tech conferences" as requiring "1) two women speaking 2) on the same panel 3) not about women in tech." If we replace "tech conference" with "academic conference" and "women in tech" with "women in DH," a Rogati-Bechdel test would reveal that #s280 (the disrupting panel), #s411 (the pedagogy panel), and #s508 (the repair panel) _all_ passed.

For a panel's Twitter feed to pass such a test, however, more probing is necessary. Does a panel's Twitter stream add more female voices or scholarship _beyond_ the female panelists or female scholars invoked by the panelists? And when panelists are women, or cite female scholars, do women's presentations and everyone's citations of female scholars get taken up equitably in the stream (or even elaborated upon?) Are female tweeters using Twitter to converse with one another? Are female DH scholars cited in other contexts than feminism or feminist DH? Finally, are women's tweets treated with the same kinds of respect and attention as men's tweets? Are they favorited, retweeted, or responded to at the same rate? Are they more or less likely to be neglected or criticized in ways that men's tweets are not?

## The DuVernay Test

Manohla Dargis recently devised a race-based analog to the Bechdel test, the "DuVernay test," in her [coverage of the Sundance Film Festival for the _New York Times_](http://www.nytimes.com/2016/01/30/movies/sundance-fights-tide-with-films-like-the-birth-of-a-nation.html). Dargis notes that, despite of the efforts of some film industry denizens to "turn Sundance into a snowy exurb of Hollywood, the festival continues to push against the mainstream tide through some of its selections" (par. 2), particularly through films like _The Birth of a Nation_, _Christine_, and _Sand Storm_. Referencing _Selma_ director [Ava DuVernay](http://www.avaduvernay.com/), Dargis writes that "such films pass what might be called the DuVernay test, in which African-Americans and other minorities have fully realized lives rather than serve as scenery in white stories" (par. 6). Dargis's conclusion---"For women, for minorities, for those seeking something different, it can be hard to love movies, because they donâ€™t always love us back. Sundance makes it easier" (par. 10)---suggests the stakes for tracing tweeting as an activity that is gendered and, indeed, raced. Twitter can be seen as a potential Sundance for women of color (and women more generally), offering an opportunity for keen Twitter users to use the medium to reflect their own research interests and their own scholarly communities. 

Although I did not actively track the racial identification of all the tweeters or persons mentioned in tweets, and therefore cannot confirm the representational equity or diversity of this dataset with hard numbers, I will suggest that, in particular, [the tweets from the "Disrupting the Digital Humanities" panel](https://storify.com/clancynewyork/disrupting-dh) provide the kind of "an exhilarating, multifaceted portrait," particularly refreshing for "those seeking something different," that [Dargis writes about](http://www.nytimes.com/2016/01/30/movies/sundance-fights-tide-with-films-like-the-birth-of-a-nation.html) (par. 9). What I can truly offer, however, is a short (no doubt incomplete) list of guidelines for what Dargis's standard of "fully realized lives" might translate into for academic Twitter: first, that minority presenters are equally represented; second, that minority audience members are represented and listened to; third, that minority tweeters feel free to express any concerns about any race-related issues raised by the presentations; and fourth, that accounts of scholarship by people of color are abundant, nuanced, and regarded as central to the Twitter stream, rather than as a peripheral or "boutique" concern.

## Gender Identification

To sort tweets into gendered data, I applied categories (man, woman, or no gender identified) based on the tweeter as well as any person mentioned in the tweet. To determine gender, I relied in most cases on my prior or subsequent acquaintance with the person and his/her/their Twitter persona. For other cases, on what I regarded as publicly available signifiers of gender presentation, such as clothing and pronouns. For those I did not remember from MLA, I sought only readily available information put up online _by that person_, as any other effort would be invasive. It was a clumsy system, very unsubtle and reliant on my undoubtedly subjective perceptions of gendered categories that themselves are limited and limiting. 

Despite these reservations, I hope to limit the negative effects of this initial choice to use a gender binary by not identifying particular tweeters' identities in my data (particularly in the downloadable Excel data) or at any point in this written discussion, not guessing individual tweeters' _intentions_ (and thereby making further gendered assumptions about them), and not tracking the particular set of tweets by an individual. The only exception, as I discuss in the Methods section, was in the case of the two super-tweeters, in which case it was advisable to provide data both including and exclusing them to determine if super-tweeters skew results. 

I am not aiming to theorize timeless gender categories or behaviors. Rather, I am concerned here with the "optics" of what happened _there and then_, on the panel's Twitter feed, and I have tried to circumscribe by discussion of what happened within a very specific context. A different presentation of the same data could, for example, slice up by data by comparing casual, active, and super-tweeters (as defined in the Methods section), rather than breaking it down by gender lines. The observations that are here represented as a gendered issue could thus be reframed as a matter of individual tweeting patterns. Still, I stand by this case study as a contribution to the very necessary work being done in the feminist digital humanities, particularly because those who would identify as _digital_ humanists are probably chiefly represented in this dataset (as discussed above). Finding new ways to describe, define, and support the work of women done in the digital humanities is, I think, an important contribution to that work.